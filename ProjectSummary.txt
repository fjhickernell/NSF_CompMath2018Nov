%%%%%%%%%%%
Overview:
%%%%%%%%%%%
Multivariate integration and function approximation arise in applications including financial risk management, statistical physics, surrogate modeling of computer experiments, and uncertainty quantification.  Algorithms are needed that adaptively and automatically determine the computational effort needed to meet the prescribed error tolerance.  Existing adaptive algorithms rely on heuristics and lack a theoretical foundation. Theoretically sound error bounds are inadequate for adaptive algorithms because they require unreasonable a priori information, such as the (semi-)norm of the input function. The proposed research will rectify this deficiency by deriving data-driven error bounds that are guaranteed to work on a cone of input functions.  These data-driven error bounds will be used to construct theoretically sound adaptive algorithms.  These new adaptive algorithms will be implemented in an open source software library.



%%%%%%%%%%%
Intellectual Merit:
%%%%%%%%%%%
The key idea is to identify and precisely define cones of input functions that are not too spiky.  For such functions, what is not observed is not much worse than what is observed by a reasonable number of function values at well-chosen nodes.  For such cones of non-spiky functions one can construct data-driven error bounds that certainly hold.  Adaptive algorithms proceed by increasing the number of nodes used for integration or approximation until the data-driven error bounds do not exceed the error tolerance.  This research will construct several new adaptive algorithms following the above paradigm and building upon the previous work of the PIs.

Multivariate Integration:  The fast, Bayesian cubature already developed for lattice sampling, will be applied to (high order) digital net sampling and matching kernels.  By choosing nodes and kernels to match, the matrix operations required can be quick.  Existing quasi-Monte Carlo (QMC) multivariate integration algorithms will be extended to adaptive infinite-dimensional integration algorithms using multi-level and/or multivariate decomposition ideas.  

Multivariate Function Approximation:  The tractability of general linear problems defined on cones of input functions will be determined.  The fast, Bayesian framework for cubature will be employed for function approximation.  In some situations, function values come from simulations that take hours or days.  Limited by the practical constraint where the number of function values is roughly proportional to the number of variables, new adaptive algorithms will be constructed that adaptively identify important variables through an initial screening sample, and then sample more strategically.

Univariate Problems: Previously constructed low-order, adaptive univariate integration and optimization algorithms will be upgraded to high-order adaptive algorithms.  This will make them as fast as commonly used algorithms but having a firmer theoretical foundation.



%%%%%%%%%%%
Broader Impacts:
%%%%%%%%%%%
The new algorithms developed will be published in a variety of mathematics, statistics, and computer science journals.  They will be implemented in the freely available Guaranteed Automatic Integration Library (GAIL), which has a six year history and is in ongoing development.  Our software development efforts will be combined with those of other QMC research groups to form a community QMC software library, QMCSoft.  The effectiveness of our algorithms will be demonstrated on standard test functions and through collaborations with practitioners.  High school students through early career scholars will be mentored in conducting research with a sound theoretical foundation and with practical application.  These new mentees will join dozens who have already contributed to past NSF-funded research on theoretically sound, adaptive algorithms. 
